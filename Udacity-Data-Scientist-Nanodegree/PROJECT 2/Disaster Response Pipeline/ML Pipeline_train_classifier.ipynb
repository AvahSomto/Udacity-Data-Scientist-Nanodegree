{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ML Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Import libraries and load data from database."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Just\n",
      "[nltk_data]     Me\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Just\n",
      "[nltk_data]     Me\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "nltk.download(['punkt', 'wordnet'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T04:20:24.383048Z",
     "start_time": "2023-08-17T04:20:17.120786600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql_table(\"disaster_messages\", con=engine)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T04:20:25.439972500Z",
     "start_time": "2023-08-17T04:20:24.386040600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Display df dataframe\n",
    "df = pd.read_sql(\"SELECT * from disaster_messages\",con=engine)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T04:20:26.142680500Z",
     "start_time": "2023-08-17T04:20:25.441969900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df.iloc[:, 4:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T04:20:26.158783700Z",
     "start_time": "2023-08-17T04:20:26.147667Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(disaster_text):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to tokenize text.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = word_tokenize(disaster_text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens=[]\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T04:20:26.189867400Z",
     "start_time": "2023-08-17T04:20:26.163901400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Build a machine learning pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Building an ML pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T04:20:26.190865800Z",
     "start_time": "2023-08-17T04:20:26.172536400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Train pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T04:20:26.272857Z",
     "start_time": "2023-08-17T04:20:26.241412100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Just Me\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-17T04:20:26.241412100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Test your model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make a prediction using the test set\n",
    "y_pred = pipeline.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def test_model(y_test, y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to iterate through columns and call sklearn classification report on each.\n",
    "    \"\"\"\n",
    "    for index, column in enumerate(y_test):\n",
    "        print(column, classification_report(y_test[column], y_pred[:, index]))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing the model using the test and the prediction\n",
    "test_model(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Improve your model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using grid search to find better parameters\n",
    "pipeline.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specifying parameters for grid search\n",
    "parameters = {\n",
    "    'clf__estimator__n_estimators' : [50, 150]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "cv"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit the train datasets\n",
    "cv.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using cv to find the best parameter\n",
    "cv.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Test your model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Performing predictions on the test dataset using cv\n",
    "y_pred = cv.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the model using the test and prediction dataset\n",
    "test_model(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Displaying the accuracy score\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. Try improving your model further."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from custom_transformer import StartingVerbExtractor\n",
    "from sklearn import multioutput\n",
    "\n",
    "#trying to add another feature.\n",
    "\n",
    "upd_pipeline = Pipeline([\n",
    "    ('features', FeatureUnion ([\n",
    "\n",
    "        ('text_pipeline', Pipeline ([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('starting_verb', StartingVerbExtractor ())\n",
    "    ])),\n",
    "\n",
    "    ('clf', multioutput.MultiOutputClassifier (RandomForestClassifier ()))\n",
    "])\n",
    "\n",
    "# train SVM classifier\n",
    "upd_pipeline.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_upd = upd_pipeline.predict (X_test)\n",
    "#converting to dataframe\n",
    "y_pred_upd = pd.DataFrame (y_pred_upd, columns = y_test.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Export your model as a pickle file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = 'classifier.pkl'\n",
    "pickle.dump(cv, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
